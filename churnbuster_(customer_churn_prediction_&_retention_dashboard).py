#start#
# -*- coding: utf-8 -*-
"""ChurnBuster (Customer Churn Prediction & Retention Dashboard).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c5xDhH4M9vBfKrG6Y3j_mNG4xzsffBV5
"""

# Uninstall current pyngrok (v6+)
!pip uninstall pyngrok -y

# Install compatible pyngrok
!pip install pyngrok==5.2.1 xgboost shap streamlit --quiet

# Add your ngrok authtoken here
NGROK_AUTHTOKEN = "37wLo9kxLkDmJmNAA9gIoogMsIU_2SA3ynwHC2QHjWZNEov66"  # <-- Replace with your token

!ngrok authtoken {NGROK_AUTHTOKEN}

import pandas as pd
import numpy as np
import xgboost as xgb
import shap
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, roc_auc_score

from pyngrok import ngrok

df = pd.read_csv("/content/WA_Fn-UseC_-Telco-Customer-Churn.csv")
print("Dataset Shape:", df.shape)
df.head()

df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)

cat_cols = df.select_dtypes(include='object').columns
for col in cat_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])

X = df.drop(['Churn', 'customerID'], axis=1)
y = df['Churn']

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    stratify=y,
    random_state=42
)

neg, pos = np.bincount(y_train)
scale_pos_weight = neg / pos
print("Scale pos weight:", scale_pos_weight)

model = xgb.XGBClassifier(
    n_estimators=350,
    max_depth=5,
    learning_rate=0.05,
    subsample=0.85,
    colsample_bytree=0.85,
    scale_pos_weight=scale_pos_weight,
    objective='binary:logistic',
    eval_metric='auc',
    random_state=42
)

model.fit(X_train, y_train)

y_prob = model.predict_proba(X_test)[:, 1]
y_pred = model.predict(X_test)

print("ROC-AUC Score:", round(roc_auc_score(y_test, y_prob), 3))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

COST_FN = 500
COST_FP = 50

thresholds = np.arange(0.1, 0.9, 0.01)
costs = []

for t in thresholds:
    y_t = (y_prob >= t).astype(int)
    fp = ((y_t == 1) & (y_test == 0)).sum()
    fn = ((y_t == 0) & (y_test == 1)).sum()
    costs.append(fp * COST_FP + fn * COST_FN)

optimal_threshold = thresholds[np.argmin(costs)]
print("Optimal threshold:", round(optimal_threshold, 2))

y_opt = (y_prob >= optimal_threshold).astype(int)
print("\nClassification Report at Optimal Threshold:\n")
print(classification_report(y_test, y_opt))

plt.plot(thresholds, costs)
plt.axvline(optimal_threshold, color='red', linestyle='--')
plt.xlabel("Threshold")
plt.ylabel("Total Cost")
plt.title("Cost-Based Threshold Optimization")
plt.show()

explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)

# Global importance
shap.summary_plot(shap_values, X_test, plot_type="bar")

# Detailed summary
shap.summary_plot(shap_values, X_test)

# Individual customer
idx = 10
shap.force_plot(
    explainer.expected_value,
    shap_values[idx],
    X_test.iloc[idx],
    matplotlib=True
)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import numpy as np
# import xgboost as xgb
# from sklearn.preprocessing import LabelEncoder
# 
# st.set_page_config(page_title="Customer Churn Dashboard", layout="wide")
# st.title("ðŸ“‰ Customer Churn Prediction Dashboard")
# 
# df = pd.read_csv("/content/WA_Fn-UseC_-Telco-Customer-Churn.csv")
# df['Churn'] = df['Churn'].map({'Yes':1,'No':0})
# df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
# df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)
# 
# cat_cols = df.select_dtypes(include='object').columns
# for col in cat_cols:
#     le = LabelEncoder()
#     df[col] = le.fit_transform(df[col])
# 
# X = df.drop(['Churn','customerID'], axis=1)
# y = df['Churn']
# 
# model = xgb.XGBClassifier(
#     n_estimators=300,
#     max_depth=5,
#     learning_rate=0.05,
#     subsample=0.85,
#     colsample_bytree=0.85,
#     scale_pos_weight=(y==0).sum()/(y==1).sum(),
#     eval_metric='auc'
# )
# model.fit(X, y)
# 
# df['Churn_Probability'] = model.predict_proba(X)[:,1]
# 
# threshold = st.slider("Churn Risk Threshold", 0.1, 0.9, 0.4)
# df['High_Risk'] = df['Churn_Probability'] >= threshold
# 
# col1, col2, col3 = st.columns(3)
# col1.metric("Total Customers", len(df))
# col2.metric("High-Risk Customers", df['High_Risk'].sum())
# col3.metric("Avg Churn Probability", round(df['Churn_Probability'].mean(),2))
# 
# st.subheader("High-Risk Customers")
# st.dataframe(df[df['High_Risk']].sort_values("Churn_Probability", ascending=False).head(20))
#

# Run Streamlit
get_ipython().system_raw("streamlit run app.py &")

# Create ngrok tunnel
public_url = ngrok.connect(8501)
print("Your Streamlit Dashboard URL:", public_url)



